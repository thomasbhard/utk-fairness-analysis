{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "utkface_training_full_weights.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.6 64-bit"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "interpreter": {
      "hash": "41a84036aa604917d7497ee77bf20aadd6bf6e037d12a4d13ab984fb2ace29af"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!unzip UTKFaceFull.zip"
      ],
      "outputs": [],
      "metadata": {
        "id": "aMlmEhY64wwj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "source": [
        "import os\r\n",
        "import glob\r\n",
        "\r\n",
        "import numpy as np \r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "dataset_folder_name = 'dataset/UTKFace'\r\n",
        "outputfile_name = \"df_predictions_all_test.csv\"\r\n",
        "\r\n",
        "\r\n",
        "TRAIN_TEST_SPLIT = 0.7\r\n",
        "IM_WIDTH = IM_HEIGHT = 198\r\n",
        "\r\n",
        "TRAIN_WITH_WEIGTHS = True\r\n",
        "\r\n",
        "dataset_dict = {\r\n",
        "    'race_id': {\r\n",
        "        0: 'white', \r\n",
        "        1: 'black', \r\n",
        "        2: 'asian', \r\n",
        "        3: 'indian', \r\n",
        "        4: 'others'\r\n",
        "    },\r\n",
        "    'gender_id': {\r\n",
        "        0: 'male',\r\n",
        "        1: 'female'\r\n",
        "    }\r\n",
        "}\r\n",
        "\r\n",
        "dataset_dict['gender_alias'] = dict((g, i) for i, g in dataset_dict['gender_id'].items())\r\n",
        "dataset_dict['race_alias'] = dict((g, i) for i, g in dataset_dict['race_id'].items())"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "source": [
        "#weights = {'female': {'white': {'weight': 1.0000859768999493, 'total': 1388}, 'black': {'weight': 1.0000947320909475, 'total': 655}, 'asian': {'weight': 0.9996453453531876, 'total': 568}, 'indian': {'weight': 1.000131283142888, 'total': 523}, 'others': {'weight': 1.0001248417406206, 'total': 298}}, 'male': {'white': {'weight': 1.00007922120209, 'total': 1616}, 'black': {'weight': 0.9998653674745138, 'total': 681}, 'asian': {'weight': 0.999727850814823, 'total': 459}, 'indian': {'weight': 0.9999673852528987, 'total': 637}, 'others': {'weight': 1.0001095340344832, 'total': 215}}}\r\n",
        "weights = {'female': 1.1, 'male': 0.90}\r\n",
        "                  #sample_weights.append(weights[dataset_dict['gender_id'][gender]][dataset_dict['race_id'][race]]['weight'])\r\n",
        "\r\n",
        "def get_weight(gender, age, race):\r\n",
        "    return weights[dataset_dict['gender_id'][gender]]\r\n",
        "\r\n",
        "\r\n",
        "get_weight(0,0,0)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "source": [
        "def parse_dataset(dataset_path, ext='jpg'):\r\n",
        "    \"\"\"\r\n",
        "    Used to extract information about our dataset. It does iterate over all images and return a DataFrame with\r\n",
        "    the data (age, gender and sex) of all files.\r\n",
        "    \"\"\"\r\n",
        "    def parse_info_from_file(path):\r\n",
        "        \"\"\"\r\n",
        "        Parse information from a single file\r\n",
        "        \"\"\"\r\n",
        "        try:\r\n",
        "            filename = os.path.split(path)[1]\r\n",
        "            filename = os.path.splitext(filename)[0]\r\n",
        "            age, gender, race, _ = filename.split('_')\r\n",
        "\r\n",
        "            return int(age), dataset_dict['gender_id'][int(gender)], dataset_dict['race_id'][int(race)]\r\n",
        "        except Exception as ex:\r\n",
        "            return None, None, None\r\n",
        "        \r\n",
        "    files = glob.glob(os.path.join(dataset_path, \"*.%s\" % ext))\r\n",
        "    \r\n",
        "    records = []\r\n",
        "    for file in files:\r\n",
        "        info = parse_info_from_file(file)\r\n",
        "        records.append(info)\r\n",
        "        \r\n",
        "    df = pd.DataFrame(records)\r\n",
        "    df['file'] = files\r\n",
        "    df.columns = ['age', 'gender', 'race', 'file']\r\n",
        "    df = df.dropna()\r\n",
        "    \r\n",
        "    return df\r\n",
        "\r\n",
        "\r\n",
        "df = parse_dataset(dataset_folder_name)\r\n",
        "print(df.head())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     age  gender   race                                               file\n",
            "0  100.0    male  white  dataset/UTKFace\\100_0_0_20170112213500903.jpg....\n",
            "1  100.0    male  white  dataset/UTKFace\\100_0_0_20170112215240346.jpg....\n",
            "2  100.0  female  white  dataset/UTKFace\\100_1_0_20170110183726390.jpg....\n",
            "3  100.0  female  white  dataset/UTKFace\\100_1_0_20170112213001988.jpg....\n",
            "4  100.0  female  white  dataset/UTKFace\\100_1_0_20170112213303693.jpg....\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "source": [
        "class UtkFaceDataGenerator():\r\n",
        "    \"\"\"\r\n",
        "    Data generator for the UTKFace dataset. This class should be used when training our Keras multi-output model.\r\n",
        "    \"\"\"\r\n",
        "    def __init__(self, df):\r\n",
        "        self.df = df\r\n",
        "        \r\n",
        "    def generate_split_indexes(self):\r\n",
        "        p = np.random.RandomState(seed=42).permutation(len(self.df))\r\n",
        "        train_up_to = int(len(self.df) * TRAIN_TEST_SPLIT)\r\n",
        "        train_idx = p[:train_up_to]\r\n",
        "        test_idx = p[train_up_to:]\r\n",
        "\r\n",
        "        train_up_to = int(train_up_to * TRAIN_TEST_SPLIT)\r\n",
        "        train_idx, valid_idx = train_idx[:train_up_to], train_idx[train_up_to:]\r\n",
        "        \r\n",
        "        # converts alias to id\r\n",
        "        self.df['gender_id'] = self.df['gender'].map(lambda gender: dataset_dict['gender_alias'][gender])\r\n",
        "        self.df['race_id'] = self.df['race'].map(lambda race: dataset_dict['race_alias'][race])\r\n",
        "\r\n",
        "        self.max_age = self.df['age'].max()\r\n",
        "        \r\n",
        "        return train_idx, valid_idx, test_idx\r\n",
        "    \r\n",
        "    def preprocess_image(self, img_path):\r\n",
        "        \"\"\"\r\n",
        "        Used to perform some minor preprocessing on the image before inputting into the network.\r\n",
        "        \"\"\"\r\n",
        "        im = Image.open(img_path)\r\n",
        "        im = im.resize((IM_WIDTH, IM_HEIGHT))\r\n",
        "        im = np.array(im) / 255.0\r\n",
        "        \r\n",
        "        return im\r\n",
        "        \r\n",
        "    def generate_images(self, image_idx, is_training, batch_size=16, include_weights=False, include_files=False):\r\n",
        "        \"\"\"\r\n",
        "        Used to generate a batch with images when training/testing/validating our Keras model.\r\n",
        "        \"\"\"\r\n",
        "        \r\n",
        "        # arrays to store our batched data\r\n",
        "        images, ages, races, genders = [], [], [], []\r\n",
        "\r\n",
        "        # weights\r\n",
        "        sample_weights = []\r\n",
        "        files = []\r\n",
        "        while True:\r\n",
        "            for idx in image_idx:\r\n",
        "                person = self.df.iloc[idx]\r\n",
        "                \r\n",
        "                age = person['age']\r\n",
        "                race = person['race_id']\r\n",
        "                gender = person['gender_id']\r\n",
        "                file = person['file']\r\n",
        "                \r\n",
        "                \r\n",
        "\r\n",
        "\r\n",
        "                im = self.preprocess_image(file)\r\n",
        "                \r\n",
        "                ages.append(age / self.max_age)\r\n",
        "                races.append(to_categorical(race, len(dataset_dict['race_id'])))\r\n",
        "                genders.append(to_categorical(gender, len(dataset_dict['gender_id'])))\r\n",
        "                images.append(im)\r\n",
        "                \r\n",
        "                if include_weights:\r\n",
        "                  sample_weights.append(get_weight(gender, age, race))\r\n",
        "\r\n",
        "                if include_files:\r\n",
        "                  files.append(file)\r\n",
        "\r\n",
        "                # yielding condition\r\n",
        "                if len(images) >= batch_size:\r\n",
        "                    if include_files and include_weights:\r\n",
        "                      yield np.array(images), [np.array(ages), np.array(races), np.array(genders)], np.array(sample_weights), np.array(files)\r\n",
        "                    \r\n",
        "                    elif include_files:\r\n",
        "                      yield np.array(images), [np.array(ages), np.array(races), np.array(genders)], np.array(files)\r\n",
        "\r\n",
        "                    elif include_weights:\r\n",
        "                      yield np.array(images), [np.array(ages), np.array(races), np.array(genders)], np.array(sample_weights)\r\n",
        "\r\n",
        "                    else:\r\n",
        "                      yield np.array(images), [np.array(ages), np.array(races), np.array(genders)]\r\n",
        "\r\n",
        "                    images, ages, races, genders, sample_weights, files = [], [], [], [], [], []\r\n",
        "                    \r\n",
        "            if not is_training:\r\n",
        "                break\r\n",
        "                \r\n",
        "data_generator = UtkFaceDataGenerator(df)\r\n",
        "train_idx, valid_idx, test_idx = data_generator.generate_split_indexes()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "from keras.models import Model\r\n",
        "from keras.layers import BatchNormalization\r\n",
        "from keras.layers.convolutional import Conv2D\r\n",
        "from keras.layers.convolutional import MaxPooling2D\r\n",
        "from keras.layers.core import Activation\r\n",
        "from keras.layers.core import Dropout\r\n",
        "from keras.layers.core import Lambda\r\n",
        "from keras.layers.core import Dense\r\n",
        "from keras.layers import Flatten\r\n",
        "from keras.layers import Input\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "class UtkMultiOutputModel():\r\n",
        "    \"\"\"\r\n",
        "    Used to generate our multi-output model. This CNN contains three branches, one for age, other for \r\n",
        "    sex and another for race. Each branch contains a sequence of Convolutional Layers that is defined\r\n",
        "    on the make_default_hidden_layers method.\r\n",
        "    \"\"\"\r\n",
        "    def make_default_hidden_layers(self, inputs):\r\n",
        "        \"\"\"\r\n",
        "        Used to generate a default set of hidden layers. The structure used in this network is defined as:\r\n",
        "        \r\n",
        "        Conv2D -> BatchNormalization -> Pooling -> Dropout\r\n",
        "        \"\"\"\r\n",
        "        x = Conv2D(16, (3, 3), padding=\"same\")(inputs)\r\n",
        "        x = Activation(\"relu\")(x)\r\n",
        "        x = BatchNormalization(axis=-1)(x)\r\n",
        "        x = MaxPooling2D(pool_size=(3, 3))(x)\r\n",
        "        x = Dropout(0.25)(x)\r\n",
        "\r\n",
        "        x = Conv2D(32, (3, 3), padding=\"same\")(x)\r\n",
        "        x = Activation(\"relu\")(x)\r\n",
        "        x = BatchNormalization(axis=-1)(x)\r\n",
        "        x = MaxPooling2D(pool_size=(2, 2))(x)\r\n",
        "        x = Dropout(0.25)(x)\r\n",
        "\r\n",
        "        x = Conv2D(32, (3, 3), padding=\"same\")(x)\r\n",
        "        x = Activation(\"relu\")(x)\r\n",
        "        x = BatchNormalization(axis=-1)(x)\r\n",
        "        x = MaxPooling2D(pool_size=(2, 2))(x)\r\n",
        "        x = Dropout(0.25)(x)\r\n",
        "\r\n",
        "        return x\r\n",
        "\r\n",
        "    def build_race_branch(self, inputs, num_races):\r\n",
        "        \"\"\"\r\n",
        "        Used to build the race branch of our face recognition network.\r\n",
        "        This branch is composed of three Conv -> BN -> Pool -> Dropout blocks, \r\n",
        "        followed by the Dense output layer.\r\n",
        "        \"\"\"\r\n",
        "        x = self.make_default_hidden_layers(inputs)\r\n",
        "\r\n",
        "        x = Flatten()(x)\r\n",
        "        x = Dense(128)(x)\r\n",
        "        x = Activation(\"relu\")(x)\r\n",
        "        x = BatchNormalization()(x)\r\n",
        "        x = Dropout(0.5)(x)\r\n",
        "        x = Dense(num_races)(x)\r\n",
        "        x = Activation(\"softmax\", name=\"race_output\")(x)\r\n",
        "\r\n",
        "        return x\r\n",
        "\r\n",
        "    def build_gender_branch(self, inputs, num_genders=2):\r\n",
        "        \"\"\"\r\n",
        "        Used to build the gender branch of our face recognition network.\r\n",
        "        This branch is composed of three Conv -> BN -> Pool -> Dropout blocks, \r\n",
        "        followed by the Dense output layer.\r\n",
        "        \"\"\"\r\n",
        "        x = Lambda(lambda c: tf.image.rgb_to_grayscale(c))(inputs)\r\n",
        "\r\n",
        "        x = self.make_default_hidden_layers(inputs)\r\n",
        "\r\n",
        "        x = Flatten()(x)\r\n",
        "        x = Dense(128)(x)\r\n",
        "        x = Activation(\"relu\")(x)\r\n",
        "        x = BatchNormalization()(x)\r\n",
        "        x = Dropout(0.5)(x)\r\n",
        "        x = Dense(num_genders)(x)\r\n",
        "        x = Activation(\"sigmoid\", name=\"gender_output\")(x)\r\n",
        "\r\n",
        "        return x\r\n",
        "\r\n",
        "    def build_age_branch(self, inputs):   \r\n",
        "        \"\"\"\r\n",
        "        Used to build the age branch of our face recognition network.\r\n",
        "        This branch is composed of three Conv -> BN -> Pool -> Dropout blocks, \r\n",
        "        followed by the Dense output layer.\r\n",
        "\r\n",
        "        \"\"\"\r\n",
        "        x = self.make_default_hidden_layers(inputs)\r\n",
        "\r\n",
        "        x = Flatten()(x)\r\n",
        "        x = Dense(128)(x)\r\n",
        "        x = Activation(\"relu\")(x)\r\n",
        "        x = BatchNormalization()(x)\r\n",
        "        x = Dropout(0.5)(x)\r\n",
        "        x = Dense(1)(x)\r\n",
        "        x = Activation(\"linear\", name=\"age_output\")(x)\r\n",
        "\r\n",
        "        return x\r\n",
        "\r\n",
        "    def assemble_full_model(self, width, height, num_races):\r\n",
        "        \"\"\"\r\n",
        "        Used to assemble our multi-output model CNN.\r\n",
        "        \"\"\"\r\n",
        "        input_shape = (height, width, 3)\r\n",
        "\r\n",
        "        inputs = Input(shape=input_shape)\r\n",
        "\r\n",
        "        age_branch = self.build_age_branch(inputs)\r\n",
        "        race_branch = self.build_race_branch(inputs, num_races)\r\n",
        "        gender_branch = self.build_gender_branch(inputs)\r\n",
        "\r\n",
        "        model = Model(inputs=inputs,\r\n",
        "                     outputs = [age_branch, race_branch, gender_branch],\r\n",
        "                     name=\"face_net\")\r\n",
        "\r\n",
        "        return model\r\n",
        "\r\n",
        "    def assemble_gender_only(self, width, height):\r\n",
        "        input_shape = (height, width, 3)\r\n",
        "\r\n",
        "        inputs = Input(shape=input_shape)\r\n",
        "\r\n",
        "        gender_branch = self.build_gender_branch(inputs)\r\n",
        "\r\n",
        "        model = Model(inputs=inputs,\r\n",
        "                     outputs = gender_branch,\r\n",
        "                     name=\"face_net\")\r\n",
        "\r\n",
        "        return model\r\n",
        "\r\n",
        "    \r\n",
        "model = UtkMultiOutputModel().assemble_full_model(IM_WIDTH, IM_HEIGHT, num_races=len(dataset_dict['race_alias']))\r\n",
        "\r\n",
        "model.summary()\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"face_net\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 198, 198, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 198, 198, 16) 448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 198, 198, 16) 448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 198, 198, 16) 448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 198, 198, 16) 0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 198, 198, 16) 0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 198, 198, 16) 0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 198, 198, 16) 64          activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 198, 198, 16) 64          activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 198, 198, 16) 64          activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 66, 66, 16)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 66, 66, 16)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 66, 66, 16)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 66, 66, 16)   0           max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 66, 66, 16)   0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 66, 66, 16)   0           max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 66, 66, 32)   4640        dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 66, 66, 32)   4640        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 66, 66, 32)   4640        dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 66, 66, 32)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 66, 66, 32)   0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 66, 66, 32)   0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 66, 66, 32)   128         activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 66, 66, 32)   128         activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 66, 66, 32)   128         activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 33, 33, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 33, 33, 32)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 33, 33, 32)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 33, 33, 32)   0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 33, 33, 32)   0           max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 33, 33, 32)   0           max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 33, 33, 32)   9248        dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 33, 33, 32)   9248        dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 33, 33, 32)   9248        dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 33, 33, 32)   0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 33, 33, 32)   0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 33, 33, 32)   0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 33, 33, 32)   128         activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 33, 33, 32)   128         activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 33, 33, 32)   128         activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 32)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 32)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 16, 16, 32)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 16, 16, 32)   0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 16, 16, 32)   0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 16, 16, 32)   0           max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 8192)         0           dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 8192)         0           dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 8192)         0           dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 128)          1048704     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 128)          1048704     flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 128)          1048704     flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 128)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 128)          0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 128)          0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 128)          512         activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 128)          512         activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 128)          512         activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 128)          0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 128)          0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 128)          0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            129         dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 5)            645         dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 2)            258         dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "age_output (Activation)         (None, 1)            0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "race_output (Activation)        (None, 5)            0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gender_output (Activation)      (None, 2)            0           dense_5[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 3,192,648\n",
            "Trainable params: 3,191,400\n",
            "Non-trainable params: 1,248\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ReM53Ld46Gr",
        "outputId": "1419290b-859d-47f6-ea70-32193e98081c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "from tensorflow.keras.optimizers import Adam\r\n",
        "\r\n",
        "\r\n",
        "init_lr = 1e-4\r\n",
        "epochs = 2\r\n",
        "\r\n",
        "opt = Adam(lr=init_lr, decay=init_lr / epochs)\r\n",
        "\r\n",
        "model.compile(optimizer=opt, \r\n",
        "              loss={\r\n",
        "                  'age_output': 'mse', \r\n",
        "                  'race_output': 'categorical_crossentropy', \r\n",
        "                  'gender_output': 'binary_crossentropy'},\r\n",
        "              loss_weights={\r\n",
        "                  'age_output': 4., \r\n",
        "                  'race_output': 1.5, \r\n",
        "                  'gender_output': 0.1},\r\n",
        "              metrics={\r\n",
        "                  'age_output': 'mae', \r\n",
        "                  'race_output': 'accuracy',\r\n",
        "                  'gender_output': 'accuracy'})"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "from keras.callbacks import ModelCheckpoint\r\n",
        "\r\n",
        "batch_size = 32\r\n",
        "valid_batch_size = 32\r\n",
        "train_gen = data_generator.generate_images(train_idx, is_training=True, batch_size=batch_size, include_weights=TRAIN_WITH_WEIGTHS)\r\n",
        "valid_gen = data_generator.generate_images(valid_idx, is_training=True, batch_size=valid_batch_size, include_weights=TRAIN_WITH_WEIGTHS)\r\n",
        "\r\n",
        "callbacks = [\r\n",
        "    ModelCheckpoint(\"./model_checkpoint\", monitor='val_loss')\r\n",
        "]\r\n",
        "\r\n",
        "history = model.fit(train_gen,\r\n",
        "                    steps_per_epoch=len(train_idx)//batch_size,\r\n",
        "                    epochs=epochs,\r\n",
        "                    callbacks=callbacks,\r\n",
        "                    validation_data=valid_gen,\r\n",
        "                    validation_steps=len(valid_idx)//valid_batch_size)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "362/362 [==============================] - 1500s 4s/step - loss: 15.4713 - age_output_loss: 3.0825 - race_output_loss: 2.0445 - gender_output_loss: 0.7458 - age_output_mae: 1.3666 - race_output_accuracy: 0.3465 - gender_output_accuracy: 0.6753 - val_loss: 7.5740 - val_age_output_loss: 1.1825 - val_race_output_loss: 1.8411 - val_gender_output_loss: 0.8244 - val_age_output_mae: 0.8657 - val_race_output_accuracy: 0.4675 - val_gender_output_accuracy: 0.5758\n",
            "INFO:tensorflow:Assets written to: .\\model_checkpoint\\assets\n",
            "Epoch 2/2\n",
            "362/362 [==============================] - 1308s 4s/step - loss: 8.5374 - age_output_loss: 1.5924 - race_output_loss: 1.4111 - gender_output_loss: 0.5126 - age_output_mae: 0.9752 - race_output_accuracy: 0.5247 - gender_output_accuracy: 0.7892 - val_loss: 29.2911 - val_age_output_loss: 6.7994 - val_race_output_loss: 1.3680 - val_gender_output_loss: 0.4133 - val_age_output_mae: 1.8213 - val_race_output_accuracy: 0.5442 - val_gender_output_accuracy: 0.8310\n",
            "INFO:tensorflow:Assets written to: .\\model_checkpoint\\assets\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXmta98h5AeB",
        "outputId": "a2d836a6-3562-4511-d80c-2ab3d6943139"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "source": [
        "plt.plot(history.history['gender_output_accuracy'])\r\n",
        "plt.plot(history.history['val_gender_output_accuracy'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "metadata": {
        "id": "c2ny3d36AaDg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "0b1faee9-c49c-4287-8cc4-a8ee11eec2b7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "source": [
        "test_batch_size = 128\r\n",
        "test_generator = data_generator.generate_images(test_idx, is_training=False, batch_size=test_batch_size)\r\n",
        "age_pred, race_pred, gender_pred = model.predict_generator(test_generator, \r\n",
        "                                                           steps=len(test_idx)//test_batch_size)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\thoma\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9Fij3EaUYKK",
        "outputId": "210a415c-a95b-46a7-ba51-af4d3f8e7163"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "source": [
        "test_generator = data_generator.generate_images(test_idx, is_training=False, batch_size=test_batch_size, include_weights=True, include_files=True)\r\n",
        "samples = 0\r\n",
        "images, age_true, race_true, gender_true, sample_weights, files = [], [], [], [], [], []\r\n",
        "for test_batch in test_generator:\r\n",
        "    image = test_batch[0]\r\n",
        "    labels = test_batch[1]\r\n",
        "    \r\n",
        "    images.extend(image)\r\n",
        "\r\n",
        "    age_true.extend(labels[0])\r\n",
        "    race_true.extend(labels[1])\r\n",
        "    gender_true.extend(labels[2])\r\n",
        "\r\n",
        "    sample_weights.extend(test_batch[2])\r\n",
        "    files.extend(test_batch[3])\r\n",
        "    \r\n",
        "age_true = np.array(age_true)\r\n",
        "race_true = np.array(race_true)\r\n",
        "gender_true = np.array(gender_true)\r\n",
        "\r\n",
        "race_true, gender_true = race_true.argmax(axis=-1), gender_true.argmax(axis=-1)\r\n",
        "race_pred, gender_pred = race_pred.argmax(axis=-1), gender_pred.argmax(axis=-1)\r\n",
        "\r\n",
        "age_true = age_true * data_generator.max_age\r\n",
        "age_pred = age_pred * data_generator.max_age\r\n",
        "\r\n",
        "age_pred_flat = age_pred.flatten()"
      ],
      "outputs": [],
      "metadata": {
        "id": "gyEiqloIU88y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "source": [
        "from sklearn.metrics import classification_report\r\n",
        "\r\n",
        "cr_gender = classification_report(gender_true, gender_pred, target_names=dataset_dict['gender_alias'].keys())\r\n",
        "print(cr_gender)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        male       0.85      0.80      0.82      3691\n",
            "      female       0.79      0.85      0.82      3349\n",
            "\n",
            "    accuracy                           0.82      7040\n",
            "   macro avg       0.82      0.82      0.82      7040\n",
            "weighted avg       0.82      0.82      0.82      7040\n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOdJh_kMVrka",
        "outputId": "d700d1ae-d740-439e-c504-6b15b2005f27"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "source": [
        "df_prediction = pd.DataFrame({'age_true': age_true, 'age_pred': age_pred_flat, 'race_true': race_true, 'race_pred': race_pred, 'gender_true': gender_true, 'gender_pred': gender_pred})\r\n",
        "df_prediction = df_prediction.round(0).astype(int)\r\n",
        "df_prediction['weights'] = sample_weights\r\n",
        "df_prediction['files'] = files\r\n",
        "df_prediction.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age_true</th>\n",
              "      <th>age_pred</th>\n",
              "      <th>race_true</th>\n",
              "      <th>race_pred</th>\n",
              "      <th>gender_true</th>\n",
              "      <th>gender_pred</th>\n",
              "      <th>weights</th>\n",
              "      <th>files</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>29</td>\n",
              "      <td>446</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>dataset/UTKFace\\29_0_4_20170103235840396.jpg.c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>60</td>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>dataset/UTKFace\\60_1_1_20170113185112295.jpg.c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>158</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>dataset/UTKFace\\5_1_4_20170116232419298.jpg.ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>26</td>\n",
              "      <td>-23</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.1</td>\n",
              "      <td>dataset/UTKFace\\26_1_3_20170119180953860.jpg.c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16</td>\n",
              "      <td>105</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>dataset/UTKFace\\16_0_0_20170110232450588.jpg.c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age_true  age_pred  race_true  race_pred  gender_true  gender_pred  \\\n",
              "0        29       446          4          0            0            0   \n",
              "1        60        62          1          1            1            0   \n",
              "2         5       158          4          1            1            0   \n",
              "3        26       -23          3          3            1            1   \n",
              "4        16       105          0          0            0            0   \n",
              "\n",
              "   weights                                              files  \n",
              "0      0.9  dataset/UTKFace\\29_0_4_20170103235840396.jpg.c...  \n",
              "1      1.1  dataset/UTKFace\\60_1_1_20170113185112295.jpg.c...  \n",
              "2      1.1  dataset/UTKFace\\5_1_4_20170116232419298.jpg.ch...  \n",
              "3      1.1  dataset/UTKFace\\26_1_3_20170119180953860.jpg.c...  \n",
              "4      0.9  dataset/UTKFace\\16_0_0_20170110232450588.jpg.c...  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "gZ3Aw7PGXzxS",
        "outputId": "9a3158d8-85a4-4a47-a9d7-203b51437ddd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "source": [
        "import time\r\n",
        "\r\n",
        "outfilebase = time.strftime(\"%Y%m%d-%H%M%S\", time.gmtime(time.time()))\r\n",
        "\r\n",
        "outputfile = outfilebase + '_' + outputfile_name\r\n",
        "\r\n",
        "df_prediction.to_csv(outputfile)"
      ],
      "outputs": [],
      "metadata": {
        "id": "niYf_nJcYv-B"
      }
    }
  ]
}